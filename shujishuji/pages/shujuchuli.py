import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
import os
from datetime import datetime

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå¹³å°",   
    layout="wide",    
    initial_sidebar_state="expanded"  
)

# ç¼“å­˜æ•°æ®åŠ è½½
@st.cache_data
def load_data(uploaded_file):
    try:
        return pd.read_csv(uploaded_file)
    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")
        return None


def data_preprocessing(df):
    """æ•°æ®é¢„å¤„ç†å‡½æ•°"""
    st.subheader('æ•°æ®é¢„å¤„ç†')
    
    if 'processed_data' not in st.session_state:
        st.session_state.processed_data = df.copy()

    
    with st.form('preprocessing_form'):   
        col1, col2 = st.columns(2)    
        
        with col1:
            columns_to_drop = st.multiselect(
                'é€‰æ‹©è¦åˆ é™¤çš„åˆ—',
                st.session_state.processed_data.columns,
                
                help="é€‰æ‹©ä¸éœ€è¦çš„ç‰¹å¾åˆ—"
            )
            
        with col2:
            categorical_cols = st.session_state.processed_data.select_dtypes(
                include=['object', 'category','int']).columns.tolist()  
            columns_to_encode = st.multiselect(
                'é€‰æ‹©è¦è¿›è¡Œç‹¬çƒ­ç¼–ç çš„åˆ—',
                categorical_cols,   
                
                help="é€‰æ‹©åˆ†ç±»å˜é‡è¿›è¡Œç‹¬çƒ­ç¼–ç "
            )
        
        submitted = st.form_submit_button('åº”ç”¨é¢„å¤„ç†') 
    
    if submitted:
        try:
            
            if columns_to_drop:    
                st.session_state.processed_data = st.session_state.processed_data.drop(
                    columns=columns_to_drop)
            
          
            if columns_to_encode:    
                st.session_state.processed_data = pd.get_dummies(
                    st.session_state.processed_data, 
                    columns=columns_to_encode, 
                    dtype=int
                )
            
            st.success("é¢„å¤„ç†å®Œæˆï¼")
            show_correlation_matrix(st.session_state.processed_data)

            
        except Exception as e:
            st.error(f"é¢„å¤„ç†å‡ºé”™: {str(e)}")
    
    return st.session_state.processed_data    


def show_correlation_matrix(df):
    """æ˜¾ç¤ºç›¸å…³æ€§çŸ©é˜µ"""
    st.subheader('ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
    try:
        corr_matrix = df.corr()  
        fig, ax = plt.subplots(figsize=(10,6))   
        sns.heatmap(
            corr_matrix,    
            annot=True,    
            fmt=".2f",     
            cmap='coolwarm',  
            center=0,    
            ax=ax      
        )
        # plt.title("ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾", pad=20)  
        st.pyplot(fig)    
    except Exception as e:
        st.warning(f"æ— æ³•è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ: {str(e)}")


def feature_selection(df):
    """ç‰¹å¾é€‰æ‹©ç•Œé¢"""
    st.subheader('ç‰¹å¾é€‰æ‹©')    
    
    
    if 'selected_features' not in st.session_state:
        st.session_state.selected_features = []
    if 'selected_target' not in st.session_state:
        st.session_state.selected_target = None
    
    
    with st.form('feature_selection_form'):
        col1, col2 = st.columns(2)
        
        with col1:
            features = st.multiselect(
                'é€‰æ‹©ç‰¹å¾å˜é‡',
                df.columns,
                default=st.session_state.selected_features,    
                key='feature_select'
            )
            
        with col2:
            target = st.selectbox(
                'é€‰æ‹©ç›®æ ‡å˜é‡',
                df.columns,
                index=df.columns.get_loc(st.session_state.selected_target) 
                if st.session_state.selected_target in df.columns else 0,
                key='target_select'
            )
        
        submitted = st.form_submit_button('ç¡®è®¤é€‰æ‹©')

        if submitted:
            if not features:
                st.error("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡ï¼")
                return None, None
            
            if target in features:
                st.error("âŒ ç›®æ ‡å˜é‡ä¸èƒ½åŒæ—¶ä½œä¸ºç‰¹å¾å˜é‡ï¼")
                return None, None
            
            try:
                st.session_state.selected_features = features
                st.session_state.selected_target = target
                
                st.success("âœ… ç‰¹å¾é€‰æ‹©æœ‰æ•ˆï¼")
                return df[features].values, df[target].values
            except Exception as e:
                st.error(f"æ•°æ®é€‰æ‹©é”™è¯¯: {str(e)}")
                return None, None

    return None, None



def save_model(model):
    """å°†è®­ç»ƒå¥½çš„æ¨¡å‹ä¿å­˜å¹¶æä¾›ä¸‹è½½æŒ‰é’®"""
    try:
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"model_{timestamp}.pkl"
        
        # å°†æ¨¡å‹åºåˆ—åŒ–ä¸ºå­—èŠ‚æµ
        model_bytes = pickle.dumps(model)
        
        # åˆ›å»ºä¸‹è½½æŒ‰é’®ï¼Œå¹¶æ·»åŠ å›è°ƒå‡½æ•°
        if st.download_button(
            label="ğŸ’¾ ä¸‹è½½è®­ç»ƒå¥½çš„æ¨¡å‹",
            data=model_bytes,
            file_name=filename,
            mime="application/octet-stream",
            help="ç‚¹å‡»ä¸‹è½½è®­ç»ƒå¥½çš„éšæœºæ£®æ—æ¨¡å‹",
            on_click=clear_all  # æ·»åŠ è¿™è¡Œï¼Œç‚¹å‡»æŒ‰é’®åè°ƒç”¨clear_all
        ):
            st.success("æ¨¡å‹ä¸‹è½½å®Œæˆï¼Œå·²æ¸…ç©ºä¼šè¯æ•°æ®")
            return True
    except Exception as e:
        st.error(f"æ¨¡å‹ä¿å­˜å¤±è´¥: {str(e)}")
    return False



def train_random_forest(X, y):
    """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ï¼ˆä¿®å¤ç‰ˆï¼‰"""
    st.subheader('éšæœºæ£®æ—æ¨¡å‹è®­ç»ƒ')
    
    
    if 'training_results' not in st.session_state:
        st.session_state.training_results = None
    
    if 'training_results' not in st.session_state:
        st.session_state.training_results = None
    try:

        st.session_state.training_results = None    
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # è®­ç»ƒæ¨¡å‹
        model = RandomForestClassifier(
            # n_estimators=100,
            # max_depth=3,
            # random_state=42,
            # n_jobs=-1
        )
        model.fit(X_train, y_train)
        
        # è¯„ä¼°æ¨¡å‹
        y_pred = model.predict(X_test)
        results = {
            'model': model,
            'accuracy': accuracy_score(y_test, y_pred),
            'f1': f1_score(y_test, y_pred),
            'confusion_matrix': confusion_matrix(y_test, y_pred),
            'features': X.shape[1]
        }
        
        # ä¿å­˜ç»“æœ
        st.session_state.training_results = results
        st.session_state.model = model

        pkl_filename = "moxing02.pkl"
        with open(pkl_filename,'wb') as file:
            pickle.dump(st.session_state.model,file)
        st.write('ä¿å­˜æˆåŠŸ')

        
    except Exception as e:
        st.error(f"è®­ç»ƒå¼‚å¸¸: {str(e)}")
    
    # è‡ªåŠ¨æ˜¾ç¤ºè®­ç»ƒç»“æœ
    if st.session_state.training_results:
        results = st.session_state.training_results
        st.success(f"è®­ç»ƒå®Œæˆï¼ç‰¹å¾æ•°: {results['features']}")
        
        # ä½¿ç”¨é€‰é¡¹å¡å±•ç¤ºç»“æœ
        tab1, tab2 = st.tabs(["ğŸ“Š æŒ‡æ ‡", "ğŸ“‹ æ··æ·†çŸ©é˜µ"])
        
        with tab1:
            col1, col2 = st.columns(2)
            col1.metric("å‡†ç¡®ç‡", f"{results['accuracy']:.4f}")
            col2.metric("F1åˆ†æ•°", f"{results['f1']:.4f}")
            
        with tab2:
            st.dataframe(pd.DataFrame(
                results['confusion_matrix'],
                columns=["é¢„æµ‹è´Ÿç±»", "é¢„æµ‹æ­£ç±»"],
                index=["çœŸå®è´Ÿç±»", "çœŸå®æ­£ç±»"]
            ))
        save_model(results['model'])  # æ›¿æ¢åŸæ¥çš„ä¿å­˜ä»£ç 
    return None

def clear_all():
    """æ¸…ç©ºä¼šè¯çŠ¶æ€å’Œç¼“å­˜"""
    # æ¸…ç©ºä¼šè¯çŠ¶æ€
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    
    # æ¸…ç©ºç¼“å­˜ï¼ˆå¦‚æœæœ‰ä½¿ç”¨ï¼‰
    st.cache_data.clear()
    st.cache_resource.clear()
    

def main():
    st.title("ğŸ¯ æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒå¹³å°")   
    # st.sidebar.title("å¯¼èˆª")    
    
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ CSVæ–‡ä»¶",
        type=["csv"],
        help="è¯·ä¸Šä¼ åŒ…å«è®­ç»ƒæ•°æ®çš„CSVæ–‡ä»¶"
    )
    # clear_all()
    if uploaded_file is not None:
        df = load_data(uploaded_file)
        if df is not None:
            with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹æ•°æ®", expanded=True):
                st.dataframe(df)
            

            df_processed = data_preprocessing(df)

            if df_processed is not None:
                # ç‰¹å¾é€‰æ‹©
                X, y = feature_selection(df_processed)
                
                if X is not None and y is not None:
                    # æ¨¡å‹è®­ç»ƒ
                    train_random_forest(X, y)
                    clear_all()
    # return None                


if __name__ == "__main__":
    main()
    









